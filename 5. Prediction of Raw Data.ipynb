{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b785df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to load files\n",
    "file_path = \"./final_ipynb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deff95b",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.metrics import auc, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56cf77",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48434678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data and labels\n",
    "x_test, y_test = pickle.load(open(file_path+'final_test.pkl', 'rb'))\n",
    "\n",
    "# Dictionary with useful parameters\n",
    "saved_dict = pickle.load(open(file_path+'saved_dict.pkl', 'rb'))\n",
    "# Dictionary with mode of all the columns of train data, useful for fill any values in test\n",
    "mode_dict = pickle.load(open(file_path+'mode_dict.pkl', 'rb'))\n",
    "\n",
    "# Standardscaler\n",
    "scaler = pickle.load(open(file_path+'scaler.pkl', 'rb'))\n",
    "\n",
    "# Ohehotencoders\n",
    "ohe_proto = pickle.load(open(file_path+'ohe_proto.pkl', 'rb'))\n",
    "ohe_service = pickle.load(open(file_path+'ohe_service.pkl', 'rb'))\n",
    "ohe_state = pickle.load(open(file_path+'ohe_state.pkl', 'rb'))\n",
    "\n",
    "# Best model found on train data, here it is Randomforest Classifier trained on only important features\n",
    "best_model = pickle.load(open(file_path+'rf_clf_imp.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18beb2b",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be42b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "# Data Cleaning\n",
    "#------------------------------------------------------------------------------------------\n",
    "def clean_data(data):\n",
    "    '''\n",
    "    Cleans given raw data. Performs various cleaning, removes Null and wrong values.\n",
    "    Check for columns datatype and fix them.\n",
    "    '''\n",
    "    numerical_col = data.select_dtypes(include=np.number).columns  # All the numerical columns list\n",
    "    categorical_col = data.select_dtypes(exclude=np.number).columns  # All the categorical columns list\n",
    "    \n",
    "    # Cleaning the data\n",
    "    for col in data.columns:\n",
    "        val = mode_dict[col]  # Mode value of the column in train data\n",
    "        data[col] = data[col].fillna(value=val)\n",
    "        data[col] = data[col].replace(' ', value=val)\n",
    "        data[col] = data[col].apply(lambda x:\"None\" if x==\"-\" else x)\n",
    "        # Fixing binary columns\n",
    "        if col in saved_dict['binary_col']:\n",
    "            data[col] = np.where(data[col]>1, val, data[col])\n",
    "\n",
    "    # Fixing datatype of columns\n",
    "    bad_dtypes = list(set(categorical_col) - set(saved_dict['cat_col']))\n",
    "    for bad_col in bad_dtypes:\n",
    "        data[col] = data[col].astype(float)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Feature Engineering: Apply log1p\n",
    "#------------------------------------------------------------------------------------------\n",
    "def apply_log1p(data):\n",
    "    '''\n",
    "    Performs FE on the data. Apply log1p on the specified columns create new column and remove those original columns.\n",
    "    '''\n",
    "    for col in saved_dict['log1p_col']:\n",
    "        new_col = col + '_log1p'  # New col name\n",
    "        data[new_col] = data[col].apply(np.log1p)  # Creating new column on transformed data\n",
    "        data.drop(col, axis=1, inplace=True)  # Removing old columns\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Standardizing: Mean centering an d varience scaling\n",
    "#------------------------------------------------------------------------------------------\n",
    "def standardize(data):\n",
    "    '''\n",
    "    Stanardize the given data. Performs mean centering and varience scaling.\n",
    "    Using stanardscaler object trained on train data.\n",
    "    '''\n",
    "    data[saved_dict['num_col']] = scaler.transform(data[saved_dict['num_col']])\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Onehot encoding of categorical columns\n",
    "#------------------------------------------------------------------------------------------\n",
    "def ohencoding(data):\n",
    "    '''\n",
    "    Onehot encoding the categoricla columns.\n",
    "    Add the ohe columns with the data and removes categorical columns.\n",
    "    Using Onehotencoder objects trained on train data.\n",
    "    '''\n",
    "    # Onehot encoding cat col using onehotencoder objects\n",
    "    X = ohe_service.transform(data['service'].values.reshape(-1, 1))\n",
    "    Xm = ohe_proto.transform(data['proto'].values.reshape(-1, 1))\n",
    "    Xmm = ohe_state.transform(data['state'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Adding encoding data to original data\n",
    "    data = pd.concat([data,\n",
    "                      pd.DataFrame(Xm.toarray(), columns=['proto_'+i for i in ohe_proto.categories_[0]]),\n",
    "                      pd.DataFrame(X.toarray(), columns=['service_'+i for i in ohe_service.categories_[0]]),\n",
    "                      pd.DataFrame(Xmm.toarray(), columns=['state_'+i for i in ohe_state.categories_[0]])],\n",
    "                      axis=1)\n",
    "    \n",
    "    # Removing cat columns\n",
    "    data.drop(['proto', 'service', 'state'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd959ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    \"\"\"\n",
    "    This function includes entire pipeline, from data preprocessing to making final predictions.\n",
    "    It takes take in raw data as input.\n",
    "    It returns predictions for given input. Here the input can be a single point or a set of points.\n",
    "    \"\"\"\n",
    "    # Using dataframe for data preprocessing, So if single point given as input\n",
    "    # Then converting that to DataFrame with 1 row\n",
    "    if isinstance(X, pd.core.series.Series):\n",
    "        # For single input as series\n",
    "        data = pd.DataFrame(X.values.reshape(1, -1)).copy()\n",
    "    else:\n",
    "        data = X.copy()\n",
    "    \n",
    "    # Resetting index of the given df and adding correct columns names mentioned in research paper\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.columns = saved_dict['columns']\n",
    "\n",
    "    # FE: Adding 1 new feature\n",
    "    data['network_bytes'] = data['dbytes'] + data['sbytes']\n",
    "\n",
    "    # Dropping columns not needed for prediction\n",
    "    dropable_col = saved_dict['to_drop'] + saved_dict['corr_col']\n",
    "    data.drop(columns=dropable_col, inplace=True)\n",
    "\n",
    "    # Cleaning and preprocessig\n",
    "    data = clean_data(data)\n",
    "    data = apply_log1p(data)\n",
    "    data = standardize(data)\n",
    "    data = ohencoding(data)\n",
    "\n",
    "    # Using only Important features\n",
    "    data = data.iloc[:, saved_dict['imp_indices']]\n",
    "    \n",
    "    # Predicting using best model\n",
    "    predictions = best_model.predict(data)\n",
    "    \n",
    "    # Returning predictions on the given data\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e40d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single datapoint\n",
    "y_pred = final_fun_1(x_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45881a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For few datapoints\n",
    "y_pred = final_fun_1(x_test.iloc[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "print(y_test.iloc[90:100].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For entire test data\n",
    "y_pred = final_fun_1(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score of total test data\n",
    "f1_score(y_test.values, y_pred)\n",
    "\n",
    "# same as found during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d83127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X, Y):\n",
    "    \"\"\"\n",
    "    This function includes entire pipeline, from data preprocessing to making final predictions.\n",
    "    It takes in raw data as input along with its target values.\n",
    "    It returns the metric value that has been selected for judging model's performance\n",
    "    Also retuns auc curve, confusion, precision and recall matrix\n",
    "    \"\"\"\n",
    "    # Getting target value and predicted value for the given data\n",
    "    y_true = Y.copy()\n",
    "    y_pred = final_fun_1(X) # By using final_fun_1 getting predicted values\n",
    "\n",
    "    # auc curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    # Confusion, precison and recall matrix\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = C.ravel()\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "\n",
    "    P = (C/C.sum(axis=0))\n",
    "    R =(((C.T)/(C.sum(axis=1))).T)\n",
    "\n",
    "    # Scores of test dataset\n",
    "    y_auc = auc(fpr, tpr)\n",
    "    y_f1 = f1_score(y_true, y_pred)\n",
    "    y_far = (FPR+FNR)/2  # False alarm rate\n",
    "\n",
    "    # Printing the result as a table\n",
    "    x = PrettyTable()\n",
    "    x.field_names = ['AUC', 'F1-score', 'False Alarm Rate']\n",
    "    x.add_row([y_auc, y_f1, y_far])\n",
    "    print(x)\n",
    "\n",
    "    # Plotting AUC curve\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(fpr, tpr, color='r', label=f\"AUC: {y_auc}\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Confusion, Precision, Recall Matrix\n",
    "    labels= ['non-attack', 'attack']\n",
    "    # Confusion\n",
    "    plt.figure(figsize=(18,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    sns.heatmap(C, annot=True, cmap=\"Blues\", fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    # Precision\n",
    "    plt.subplot(1,3,2)\n",
    "    sns.heatmap(P, annot=True, cmap=\"Greens\", fmt='.3f', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Precision Matrix\")\n",
    "    # Recall\n",
    "    plt.subplot(1,3,3)\n",
    "    sns.heatmap(R, annot=True, cmap=\"BuPu\", fmt='.3f', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Recall Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Retuning performance metrices\n",
    "    return y_auc, y_f1, y_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dac20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using entire data\n",
    "auc, f1, far = final_fun_2(x_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc, f1, far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a831d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
